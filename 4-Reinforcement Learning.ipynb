{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning \n",
    "\n",
    "Notice that in supervised learning, the focus is on working on past information and then deriving insights from it. In other words, we’re much focused on the past than on the present and future. \n",
    "But for data science and machine learning to become truly useful, the algorithms and systems should work on real-time situations. For instance, we require systems that learn real-time and adjusts accordingly to maximize the rewards. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Reinforcement Learning? \n",
    "\n",
    "\n",
    "In a nutshell, RL is about reinforcing the correct or desired behaviors as time passes. A reward for every correct behavior and a punishment otherwise. Recently RL was implemented to beat world champions at the game of Go and successfully play various Atari video games (although Reinforcement Learning there was more sophisticated and incorporated deep learning). As the system learns from reinforcement, it was able to achieve a goal or maximize the reward. \n",
    "\n",
    "One simple example is in the optimization of click-through rates (CTR) of online ads. Perhaps you have 10 ads that essentially say the same thing (maybe the words and designs are slightly different from one another). At first you want to know which ad performs best and yields the highest CTR. After all, more clicks could mean more prospects and customers for your business. \n",
    "\n",
    "But if you want to maximize the CTR, why not perform the adjustments as the ads are being run? In other words, don’t wait for your entire ad budget to run out before knowing which one performed best. Instead, find out which ads are performing best while they’re being run. Make adjustments early on so later only the highest-performing ads will be shown to the prospects. \n",
    "\n",
    "It’s very similar to a famous problem in probability theory about the multi-armed bandit problem. Let’s say you have a limited resource (e.g. advertising budget) and some choices (10 ad variants). How will you allocate your resource among those choices so you can maximize your gain (e.g. optimal CTR)? \n",
    "\n",
    "First, you have to “explore” and try the ads one by one. Of course, if you’re seeing that Ad 1 performs unusually well, you’ll “exploit” it and run it for the rest of the campaign. You don’t need to waste your money on underperforming ads. Stick to the winner and continuously exploit its performance. \n",
    "\n",
    "There’s one catch though. Early on Ad 1 might be performing well so we’re tempted to use it again and again. But what if Ad 2 catches up and if we let things unfold Ad 2 will produce higher gains? We’ll never know because the performance of Ad 1 was already exploited. \n",
    "\n",
    "There will always be tradeoffs in many data analysis and machine learning projects. That’s why it’s always recommended to set performance targets beforehand instead of wondering about the what-ifs later. Even in the most sophisticated techniques and algorithms, tradeoffs and constraints are always there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Supervised & Unsupervised Learning \n",
    "\n",
    "Notice that the definition of Reinforcement Learning doesn’t exactly fit under either Supervised or Unsupervised Learning. Remember that Supervised Learning is about learning through supervision and training. On the other hand, Unsupervised Learning is actually revealing or discovering insights from unstructured data (no supervision, no labels). \n",
    "\n",
    "One key difference compared to RL is in maximizing the set reward, learning from user interaction, and the ability to update itself in real time. Remember that RL is first about exploring and exploiting. In contrast, both Supervised and Unsupervised Learning can be more about passively learning from historical data (not real time). \n",
    "\n",
    "There’s a fine boundary among the 3 because all of them are still concerned about optimization in one way or another. Whichever is the case, all 3 have useful applications in both scientific and business settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Reinforcement Learning \n",
    "\n",
    "\n",
    "RL is particularly useful in many business scenarios such as optimizing click-through rates. How can we maximize the number of clicks for a headline? Take note that news stories often have limited lifespans in terms of their relevance and popularity. Given that limited resource (time), how can we immediately show the best performing headline? \n",
    "\n",
    "This is also the case in maximising the CTR of online ads. We have a limited ad budget and we want to get the most out of it. Let’s explore an example (using the data from Ads_CTR_Optimisation.csv) to better illustrate the idea: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ad 1</th>\n",
       "      <th>Ad 2</th>\n",
       "      <th>Ad 3</th>\n",
       "      <th>Ad 4</th>\n",
       "      <th>Ad 5</th>\n",
       "      <th>Ad 6</th>\n",
       "      <th>Ad 7</th>\n",
       "      <th>Ad 8</th>\n",
       "      <th>Ad 9</th>\n",
       "      <th>Ad 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ad 1  Ad 2  Ad 3  Ad 4  Ad 5  Ad 6  Ad 7  Ad 8  Ad 9  Ad 10\n",
       "0     1     0     0     0     1     0     0     0     1      0\n",
       "1     0     0     0     0     0     0     0     0     1      0\n",
       "2     0     0     0     0     0     0     0     0     0      0\n",
       "3     0     1     0     0     0     0     0     1     0      0\n",
       "4     0     0     0     0     0     0     0     0     0      0\n",
       "5     1     1     0     0     0     0     0     0     0      0\n",
       "6     0     0     0     1     0     0     0     0     0      0\n",
       "7     1     1     0     0     1     0     0     0     0      0\n",
       "8     0     0     0     0     0     0     0     0     0      0\n",
       "9     0     0     1     0     0     0     0     0     0      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('Ads_CTR_Optimisation.csv') \n",
    "dataset.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each round, the ads are displayed and it’s indicated which one/ones were clicked (0 if not clicked, 1 if clicked). As discussed earlier, the goal is to explore first, pick the winner and then exploit it. \n",
    "\n",
    "One popular way to achieve this is by Thompson Sampling. Simply, it addresses the exploration-exploitation dilemma (trying to achieve a balance) by sampling or trying the promising actions while ignoring or discarding actions that are likely to underperform. The algorithm works on probabilities and this can be expressed in code through the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "numbers_of_rewards_1 = [0] * d\n",
    "numbers_of_rewards_0 = [0] * d\n",
    "total_reward = 0\n",
    "for n in range(0, N):\n",
    "    ad = 0\n",
    "    max_random = 0\n",
    "    for i in range(0, d):\n",
    "        random_beta = random.betavariate(numbers_of_rewards_1[i] + 1, numbers_of_rewards_0[i] + 1)\n",
    "        if random_beta > max_random:\n",
    "            max_random = random_beta\n",
    "            ad = i\n",
    "    ads_selected.append(ad)\n",
    "    reward = dataset.values[n, ad]\n",
    "    if reward == 1:\n",
    "        numbers_of_rewards_1[ad] = numbers_of_rewards_1[ad] + 1\n",
    "    else:\n",
    "        numbers_of_rewards_0[ad] = numbers_of_rewards_0[ad] + 1\n",
    "    total_reward = total_reward + reward \n",
    "plt.hist(ads_selected)\n",
    "plt.title('Histogram of ads selections')\n",
    "plt.xlabel('Ads')\n",
    "plt.ylabel('Number of times each ad was selected')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the implementation of Thompson sampling can be very complex. It’s an interesting algorithm which is widely popular in online ad optimization, news article recommendation, product assortment and other business applications. \n",
    "\n",
    "There are other interesting algorithms and heuristics such as Upper Confidence Bound. The goal is to earn while learning. Instead of later analysis, our algorithm can perform and adjust in real time. We’re hoping to maximize the reward by trying to balance the tradeoff between exploration and exploitation (maximize immediate performance or “learn more” to improve future performance). It’s an interesting topic itself and if you want to dig deeper, you can read the following Thompson Sampling tutorial from Stanford: \n",
    "https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
